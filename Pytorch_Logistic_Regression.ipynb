{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pytorch Basic Logistic Regression**"
      ],
      "metadata": {
        "id": "0zZdMBNCFmtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "( My English is not good but if you do what i am saying you will be the master of pytorch and deep learnng )\n",
        "We have to do 9 steps for making a Logistic Regression Model.\n",
        "\n",
        "1. **Import all important libraries for making logistic regression model**\n",
        "2. **Get  data for your LogisticRegression Model**\n",
        "3. **Convert your datasets  into BATCHES**\n",
        "4. **Make a LogisticRegression mode**l\n",
        "5. **Get all your weapons ready for training**\n",
        "6. **Train your mode**l\n",
        "7. **Evaluate your mode**l\n",
        "8. **Save it**\n",
        "9. **Believe in yourself that you can do it**\n"
      ],
      "metadata": {
        "id": "h62cr4-8Fmkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Little Motivation** <br>\n",
        "First of all, you have to be proud of yourself because you take your first to become the next **Sam Altman**,**Mira Murati**, etc\n",
        "\n",
        "Believe me if you make your first Logistic model. transformers, stable diffusion will become a piece of cake for you, i know it's not practical in your point of view now, but be with me you will become expert in pytorch ,so lets start"
      ],
      "metadata": {
        "id": "pUFF_C_kFmcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Import all important libraries for making linear regression model**"
      ],
      "metadata": {
        "id": "ipDTMUqfHCD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  #here just assume it is used for making torch tensors and these type of stuff\n",
        "import torch.nn as nn #assume this is the thing which will help you to make your neural network\n",
        "import torch.nn.functional as F #assume this is the thing which will help you to get loss functions,optimizers etc\n",
        "from torch.utils.data  import DataLoader # for loading data into batches\n",
        "from torchvision import datasets , transforms # datasets for getting pytorch datasets,and transforms ,like here , we will convert pics into tensors with the help of transforms\n",
        "import time #for checking the time"
      ],
      "metadata": {
        "id": "i-nJuhRJ7ICE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Get data for your LogisticRegression Model**"
      ],
      "metadata": {
        "id": "0IJuzY8nHzGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.FashionMNIST(root='../dataset' , #directory where you want to save your datasets\n",
        "                                    train=True  , #getting data only for train\n",
        "                                    transform=transforms.ToTensor(), #converting pics into pytorch tensors\n",
        "                                    download=True) # if you want to download the data set\n",
        "test_dataset=datasets.FashionMNIST(root='../dataset' , #directory where you want to save your datasets\n",
        "                                   train=False,#getting data only for test\n",
        "                                   transform=transforms.ToTensor())#converting pics into pytorch tensors"
      ],
      "metadata": {
        "id": "F01-c7qr7H8o"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64 #Hyperparameter\n",
        "learning_rate=1e-3 #Hyperparameter\n",
        "num_epochs=5 #Hyperparameter\n",
        "in_dim=28*28  #input dimension\n",
        "n_class=10  #number of classes"
      ],
      "metadata": {
        "id": "aXMxnwK68ozB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Convert your datasets into BATCHES**"
      ],
      "metadata": {
        "id": "xIm9tTbAJDMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_dataset,batch_size,shuffle=True)\n",
        "test_loader=DataLoader(test_dataset,batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "NTSKpNMP7H6O"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.Make a LogisticRegression model**"
      ],
      "metadata": {
        "id": "T6kxYSffJPvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module): #first we make our LogisticRegression Class with the help of python's object-oriented programming, then we inherit base class(nn. Module) from pytorch\n",
        "  def __init__(self,in_dim,n_class):# here we are initializing our constructer(if you do not know anything about it , then go on google and see what is constructer (really its a very basic thing ))\n",
        "    super().__init__() # used to call the constructor of  base clas(nn.Module)\n",
        "    self.logistic=nn.Linear(in_dim,n_class) #Here we are initializing our weights and bias(neural network)\n",
        "                            #(in_dim,n_class)=(number of input features, number of targets,)\n",
        "  def forward(self,x): # it is necessary to call forward method because it will override the nn.model forward method\n",
        "    out=self.logistic(x)  #here we are giving our data (batches)\n",
        "    return out       #from LogisticRegression class we are getting output as a return, we we get after sending our data into this model\n"
      ],
      "metadata": {
        "id": "fi_cAHXy7H31"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=LogisticRegression(in_dim,n_class)  # Creating object(instance) for our class"
      ],
      "metadata": {
        "id": "quin9VsX7H1c"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.cuda.is_available()   #putting our model on gpu\n",
        "if device:\n",
        "  model.cuda()"
      ],
      "metadata": {
        "id": "7U6GiM1z-0Xv"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.Get all your weapons ready for training**"
      ],
      "metadata": {
        "id": "qK4SK5feKsSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss() #first weapon our loss function as know it is used for calculating loss of the model\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate) #learning rate  #2nd weapon our optimizer (for updating our model's parameters)"
      ],
      "metadata": {
        "id": "5DG5irV07HzQ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Train your model**"
      ],
      "metadata": {
        "id": "wAr3qT9WK4ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs): #initializing our for loop ,\n",
        "    print('*' * 10)\n",
        "    print(f'epoch {epoch+1}')\n",
        "    since = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    model.train()   #used before training the model\n",
        "    for i, data in enumerate(train_loader, 1): #getting index numbers with data\n",
        "        img, label = data #getting img and labels from our data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        if device:\n",
        "            img = img.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        out = model(img)  #getting our prediction from model\n",
        "        loss = criterion(out, label)  # getting loss\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(out, 1)\n",
        "        running_acc += (pred==label).float().mean()\n",
        "\n",
        "        optimizer.zero_grad() # making our gradients zero (it is necessary )\n",
        "        loss.backward()  #doing backpropagation\n",
        "        optimizer.step() #applying optimizer on it\n",
        "\n",
        "        if i % 300 == 0: #for printing losses\n",
        "            print(f'[{epoch+1}/{num_epochs}] Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}')\n",
        "    print(f'Finish {epoch+1} epoch, Loss: {running_loss/i:.6f}, Acc: {running_acc/i:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dATYW4b77Hw8",
        "outputId": "42573d48-c7f8-4767-e25d-558c036187d7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********\n",
            "epoch 1\n",
            "[1/5] Loss: 0.838111, Acc: 0.732396\n",
            "[1/5] Loss: 0.709440, Acc: 0.770339\n",
            "[1/5] Loss: 0.649793, Acc: 0.787240\n",
            "Finish 1 epoch, Loss: 0.644512, Acc: 0.788763\n",
            "**********\n",
            "epoch 2\n",
            "[2/5] Loss: 0.486695, Acc: 0.837240\n",
            "[2/5] Loss: 0.483641, Acc: 0.838542\n",
            "[2/5] Loss: 0.481339, Acc: 0.837639\n",
            "Finish 2 epoch, Loss: 0.479887, Acc: 0.837920\n",
            "**********\n",
            "epoch 3\n",
            "[3/5] Loss: 0.462416, Acc: 0.840521\n",
            "[3/5] Loss: 0.452967, Acc: 0.844974\n",
            "[3/5] Loss: 0.448803, Acc: 0.846910\n",
            "Finish 3 epoch, Loss: 0.448202, Acc: 0.847115\n",
            "**********\n",
            "epoch 4\n",
            "[4/5] Loss: 0.437581, Acc: 0.848385\n",
            "[4/5] Loss: 0.433242, Acc: 0.851068\n",
            "[4/5] Loss: 0.432267, Acc: 0.851215\n",
            "Finish 4 epoch, Loss: 0.431645, Acc: 0.851429\n",
            "**********\n",
            "epoch 5\n",
            "[5/5] Loss: 0.422060, Acc: 0.854531\n",
            "[5/5] Loss: 0.420352, Acc: 0.855703\n",
            "[5/5] Loss: 0.420398, Acc: 0.855382\n",
            "Finish 5 epoch, Loss: 0.420986, Acc: 0.855144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Evaluate your model**"
      ],
      "metadata": {
        "id": "SyiqFixJLPzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    model.eval()  #for checking how good is your model on the test dataset  (for evaluation )\n",
        "    eval_loss = 0.\n",
        "    eval_acc = 0.\n",
        "    for data in test_loader:\n",
        "        img, label = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        if device:\n",
        "            img = img.cuda()\n",
        "            label = label.cuda()\n",
        "        with torch.no_grad(): # because here we do not need gradients because we are just testing our model,\n",
        "            out = model(img)\n",
        "            loss = criterion(out, label)\n",
        "        eval_loss += loss.item()\n",
        "        _, pred = torch.max(out, 1) #getting prediction from our model for testing the result\n",
        "        eval_acc += (pred == label).float().mean()\n",
        "    print(f'Test Loss: {eval_loss/len(test_loader):.6f}, Acc: {eval_acc/len(test_loader):.6f}')\n",
        "    print(f'Time:{(time.time()-since):.1f} s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjA5SvaU7Huk",
        "outputId": "a6af3724-c1c4-4ce6-bdf6-66e5ed220345"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.458180, Acc: 0.837480\n",
            "Time:11.0 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.Save it**"
      ],
      "metadata": {
        "id": "vhY5E7LVLkyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), './logstic.pth')"
      ],
      "metadata": {
        "id": "oA037Zj07HsN"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9.Belive in yourself that you can do it**"
      ],
      "metadata": {
        "id": "8SVsCg6tLpTw"
      }
    }
  ]
}